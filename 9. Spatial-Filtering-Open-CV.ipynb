{"cells":[{"cell_type":"markdown","id":"63d8953e-a42f-4851-832a-6071acde39df","metadata":{},"outputs":[],"source":["<p>\n","    <a href=\"https://skills.network\" target=\"_blank\">\n","    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\">\n","    </a>\n","</p>\n"]},{"cell_type":"markdown","id":"22b72c5e-f856-4e88-b1d7-59970f4500d0","metadata":{},"outputs":[],"source":["<h1> Geometric Operations and Other Mathematical Tools with OpenCV</h1>\n"]},{"cell_type":"markdown","id":"062ad971-4d42-479c-9e29-110d4321cba1","metadata":{},"outputs":[],"source":["Estimated time needed: **40** minutes\n"]},{"cell_type":"markdown","id":"3834da51-4305-47f6-8302-b4066b8b31dc","metadata":{},"outputs":[],"source":["<h2> Spatial Operations in Image Processing</h2>\n"]},{"cell_type":"markdown","id":"b0e6c533-4ac2-4bc7-94c3-9d954b5ae11b","metadata":{},"outputs":[],"source":["Spatial operations use  pixels in a neighborhood to determine the present pixel value. Applications include filtering and sharpening. They are used in many steps in computer vision like segmentation and are a key building block in Artificial Intelligence algorithms.\n"]},{"cell_type":"markdown","id":"a5f4096b-5543-4dde-b434-13e8b511e8de","metadata":{},"outputs":[],"source":["- Linear Filtering\n","    - Filtering Noise\n","    - Gaussian Blur\n","    - Image Sharpening\n","- Edges\n","- Median\n","- Threshold\n"]},{"cell_type":"markdown","id":"7d3d3919-5986-4ea4-818b-13036bc68a5b","metadata":{},"outputs":[],"source":["* * *\n"]},{"cell_type":"markdown","id":"6794486c-7261-4a02-ab4b-fb873c821796","metadata":{},"outputs":[],"source":["Download the images for the lab\n"]},{"cell_type":"code","id":"e2fd13e3-b8ce-4ac9-b337-4996fcfe4737","metadata":{},"outputs":[],"source":["!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-CV0101EN-SkillsNetwork/images%20/images_part_1/cameraman.jpeg\n!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-CV0101EN-SkillsNetwork/images%20/images_part_1/lenna.png\n!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-CV0101EN-SkillsNetwork/images%20/images_part_1/barbara.png   "]},{"cell_type":"markdown","id":"5c0dc921-be12-4719-828b-cc3a54f9baa3","metadata":{},"outputs":[],"source":["We will import the following libraries\n"]},{"cell_type":"code","id":"8410f388-1a4c-4276-af7c-d801e578d07b","metadata":{},"outputs":[],"source":["# Used to view the images\nimport matplotlib.pyplot as plt\n# Used to perform filtering on an image\nimport cv2\n# Used to create kernels for filtering\nimport numpy as np"]},{"cell_type":"markdown","id":"50f04f07-d467-48ff-830d-bde6395fb575","metadata":{},"outputs":[],"source":["This function will plot two images side by side \n"]},{"cell_type":"code","id":"5249947a-dd5e-4d9f-b46f-59c6860b268d","metadata":{},"outputs":[],"source":["def plot_image(image_1, image_2,title_1=\"Orignal\",title_2=\"New Image\"):\n    plt.figure(figsize=(10,10))\n    plt.subplot(1, 2, 1)\n    plt.imshow(cv2.cvtColor(image_1, cv2.COLOR_BGR2RGB))\n    plt.title(title_1)\n    plt.subplot(1, 2, 2)\n    plt.imshow(cv2.cvtColor(image_2, cv2.COLOR_BGR2RGB))\n    plt.title(title_2)\n    plt.show()"]},{"cell_type":"markdown","id":"b3c32702-265b-4b92-94d3-1b152d85d99f","metadata":{},"outputs":[],"source":["Spatial operations use the nanoring pixels to determine the present pixel value \n"]},{"cell_type":"markdown","id":"2e780c14-31e4-49b5-8762-6e74137d74eb","metadata":{},"outputs":[],"source":["## Linear  Filtering\n"]},{"cell_type":"markdown","id":"626a1988-32db-4de6-9a28-6d2e8dd332af","metadata":{},"outputs":[],"source":["Filtering involves enhancing an image, for example removing the Noise from an image. Noise is caused by a bad camera or bad image compression. The same factors that cause noise may lead to blurry images, we can apply filters to sharpening these images. Convolution is a standard way to Filter an image the filter is called the kernel and different kernels perform different tasks. In addition, Convolution is used for many of the most advanced artificial intelligence algorithms. We simply take the dot product of the kernel and as an equally-sized portion of the image. We then shift the kernel and repeat.\n"]},{"cell_type":"markdown","id":"5a3c2184-111f-436f-9516-ada83077218a","metadata":{},"outputs":[],"source":["Consider the following image:\n"]},{"cell_type":"code","id":"93598faf-d19f-4f11-8315-4e4eb110e038","metadata":{},"outputs":[],"source":["# Loads the image from the specified file\nimage = cv2.imread(\"lenna.png\")\nprint(image)\n# Converts the order of the color from BGR (Blue Green Red) to RGB (Red Green Blue) then renders the image from the array of data\nplt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))"]},{"cell_type":"markdown","id":"292d8874-89b3-4542-950a-80107e70ad06","metadata":{},"outputs":[],"source":["The images we are working with are comprised of RGB values which are values from 0 to 255. Zero means white noise, this makes the image look grainy:\n"]},{"cell_type":"code","id":"45c16a42-d00c-437c-9306-8c2847d4bb04","metadata":{},"outputs":[],"source":["# Get the number of rows and columns in the image\nrows, cols,_= image.shape\n# Creates values using a normal distribution with a mean of 0 and standard deviation of 15, the values are converted to unit8 which means the values are between 0 and 255\nnoise = np.random.normal(0,15,(rows,cols,3)).astype(np.uint8)\n# Add the noise to the image\nnoisy_image = image + noise\n# Plots the original image and the image with noise using the function defined at the top\nplot_image(image, noisy_image, title_1=\"Orignal\",title_2=\"Image Plus Noise\")"]},{"cell_type":"markdown","id":"e1ae6df4-ba4f-4846-a04f-80412057b8b3","metadata":{},"outputs":[],"source":["When adding noise to an image sometimes the value might be greater than 255, in this case, 256, is subtracted from the value to wrap the number around keeping it between 0 and 255. For example, consider an image with an RGB value of 137 and we add noise with an RGB value of 215 we get an RGB value of 352. We then subtract 256, the total number of possible values between 0 and 255, to get a number between 0 and 255.\n"]},{"cell_type":"markdown","id":"16b14064-7a40-427e-a272-313b576905db","metadata":{},"outputs":[],"source":["### Filtering Noise\n"]},{"cell_type":"markdown","id":"bcd684e3-5376-4465-8c4b-1dd3a23147fa","metadata":{},"outputs":[],"source":["Smoothing filters average out the Pixels within a neighborhood, they are sometimes called low pass filters. For mean filtering, the  kernel simply averages out the kernels in a neighborhood.\n"]},{"cell_type":"code","id":"815e0d7f-743e-4d53-b79f-301fe8fe88da","metadata":{},"outputs":[],"source":["# Create a kernel which is a 6 by 6 array where each value is 1/36\nkernel = np.ones((6,6))/36"]},{"cell_type":"markdown","id":"925a11a4-9d32-4d68-9e0c-a8d1212a39a5","metadata":{},"outputs":[],"source":["The function <code>filter2D</code> performs 2D convolution between the image <code>src</code> and the  <code>kernel</code> on each color channel independently. The parameter <a href=\"https://docs.opencv.org/master/d4/d86/group__imgproc__filter.html#filter_depths\">ddepth</a> has to do with the size of the output image, we will set it to -1 so the input and output are the same size.\n"]},{"cell_type":"code","id":"628e14d3-ca3b-40a5-b174-614e7c11f464","metadata":{},"outputs":[],"source":["# Filters the images using the kernel\nimage_filtered = cv2.filter2D(src=noisy_image, ddepth=-1, kernel=kernel)"]},{"cell_type":"markdown","id":"bc4a2406-d66f-41bf-ac89-52f5d7a2e203","metadata":{},"outputs":[],"source":["We can plot the image before and after the filtering; we see the noise is reduced, but the image is blurry:\n"]},{"cell_type":"code","id":"f08ef137-588e-49ff-8f8b-a6d38bae0f42","metadata":{},"outputs":[],"source":["# Plots the Filtered and Image with Noise using the function defined at the top\nplot_image(image_filtered, noisy_image,title_1=\"Filtered image\",title_2=\"Image Plus Noise\")"]},{"cell_type":"markdown","id":"c19cc4c1-f7dd-4b56-8d26-099a593ba2d4","metadata":{},"outputs":[],"source":["A smaller kernel keeps the image sharp, but filters less noise, here we try a 4x4 kernel\n"]},{"cell_type":"code","id":"866b3485-99f1-4a54-98f4-4f38ca05d146","metadata":{},"outputs":[],"source":["# Creates a kernel which is a 4 by 4 array where each value is 1/16\nkernel = np.ones((4,4))/16\n# Filters the images using the kernel\nimage_filtered=cv2.filter2D(src=noisy_image,ddepth=-1,kernel=kernel)\n# Plots the Filtered and Image with Noise using the function defined at the top\nplot_image(image_filtered , noisy_image,title_1=\"filtered image\",title_2=\"Image Plus Noise\")"]},{"cell_type":"markdown","id":"7f68973f-4078-4761-8f9d-c88f1cddfbeb","metadata":{},"outputs":[],"source":["### Gaussian Blur\n"]},{"cell_type":"markdown","id":"34e2b5c3-bcfe-4a9f-9800-1304fb457ce7","metadata":{},"outputs":[],"source":["The function  <code>GaussianBlur</code> convolves the source image with the specified Gaussian kernel It filters noise but does a better job of preserving the edges. It has the following parameters:\n"]},{"cell_type":"markdown","id":"c8839f08-8a5f-4607-a7c5-a7cce406ff36","metadata":{},"outputs":[],"source":["Parameters\n","\n","<p><code>src</code> input image; the image can have any number of channels, which are processed independently</p>\n","<p><code>ksize:</code> Gaussian kernel size</p>\n","<p><code>sigmaX</code> Gaussian kernel standard deviation in the X direction</p>\n","<p><code>sigmaY</code> Gaussian kernel standard deviation in the Y direction; if sigmaY is zero, it is set to be equal to sigmaX </p>\n"]},{"cell_type":"code","id":"c586d195-7ee3-4a22-8f8a-353d2f00ad95","metadata":{},"outputs":[],"source":["# Filters the images using GaussianBlur on the image with noise using a 4 by 4 kernel \nimage_filtered = cv2.GaussianBlur(noisy_image,(5,5),sigmaX=4,sigmaY=4)\n# Plots the Filtered Image then the Unfiltered Image with Noise\nplot_image(image_filtered , noisy_image,title_1=\"Filtered image\",title_2=\"Image Plus Noise\")"]},{"cell_type":"markdown","id":"de2e6c6e-c3ba-4a8c-91df-492d8122d35a","metadata":{},"outputs":[],"source":["Sigma behaves like the size of the mean filter, a larger value of sigma will make the image blurry, but you are still constrained by the size of the filter, there we set sigma to 10\n"]},{"cell_type":"code","id":"59f26634-f236-4de3-be6c-860b80f4bdb3","metadata":{},"outputs":[],"source":["# Filters the images using GaussianBlur on the image with noise using a 11 by 11 kernel \nimage_filtered = cv2.GaussianBlur(noisy_image,(11,11),sigmaX=10,sigmaY=10)\n# Plots the Filtered Image then the Unfiltered Image with Noise\nplot_image(image_filtered , noisy_image,title_1=\"filtered image\",title_2=\"Image Plus Noise\")"]},{"cell_type":"markdown","id":"1b9d61d8-a7c5-4514-88cb-9b28c4e684eb","metadata":{},"outputs":[],"source":["See what happens when you set different values of sigmaX, sigmaY, and or use  non-square kernels.\n"]},{"cell_type":"markdown","id":"16b2f928-2926-4401-bc72-19c494320f29","metadata":{},"outputs":[],"source":["### Image Sharpening\n"]},{"cell_type":"markdown","id":"16d46b9a-479c-4ec8-b7e7-47bcdc00a991","metadata":{},"outputs":[],"source":["Image Sharpening  involves smoothing the image and calculating the derivatives.  We can accomplish image sharpening by applying the following Kernel.\n"]},{"cell_type":"code","id":"ffb1d10c-0e96-4793-b2c9-2de35aeb58c1","metadata":{},"outputs":[],"source":["# Common Kernel for image sharpening\nkernel = np.array([[-1,-1,-1], \n                   [-1, 9,-1],\n                   [-1,-1,-1]])\n# Applys the sharpening filter using kernel on the original image without noise\nsharpened = cv2.filter2D(image, -1, kernel)\n# Plots the sharpened image and the original image without noise\nplot_image(sharpened , image, title_1=\"Sharpened image\",title_2=\"Image\")"]},{"cell_type":"markdown","id":"1392b89e-9d4c-4a9f-b196-0a0d403c0481","metadata":{},"outputs":[],"source":["## Edges\n"]},{"cell_type":"markdown","id":"5075d728-b173-47a3-af59-6dcd109ddd49","metadata":{},"outputs":[],"source":["Edges are where pixel intensities change. The Gradient of a function outputs the rate of change; we can approximate the gradient of a grayscale image with convolution. There are several methods to approximate the gradient, let’s use the Sobel edge detector. This combines several convolutions and finding the magnitude of the result. Consider the following image:\n"]},{"cell_type":"code","id":"9fe546ae-8ca4-4cb6-a360-90f6e4541745","metadata":{},"outputs":[],"source":["# Loads the image from the specified file\nimg_gray = cv2.imread('barbara.png', cv2.IMREAD_GRAYSCALE)\nprint(img_gray)\n# Renders the image from the array of data, notice how it is 2 diemensional instead of 3 diemensional because it has no color\nplt.imshow(img_gray ,cmap='gray')"]},{"cell_type":"markdown","id":"8ea54657-ca9e-4605-908b-01f24420ff40","metadata":{},"outputs":[],"source":["We smooth the image, this decreases changes that may be caused by noise that would  affect the gradient.\n"]},{"cell_type":"code","id":"4305ee9e-57c3-44f7-bd00-97cbd090ae02","metadata":{},"outputs":[],"source":["# Filters the images using GaussianBlur on the image with noise using a 3 by 3 kernel \nimg_gray = cv2.GaussianBlur(img_gray,(3,3),sigmaX=0.1,sigmaY=0.1)\n# Renders the filtered image\nplt.imshow(img_gray ,cmap='gray')"]},{"cell_type":"markdown","id":"5d3ac4ba-3bd0-444f-9009-2462c72a7b41","metadata":{},"outputs":[],"source":["We can approximate the derivative in the X or Y direction  using the <code>Sobel</code> function, here are the parameters:\n"]},{"cell_type":"markdown","id":"8eaeb2a6-d689-41aa-9e2c-96eb2cfebd96","metadata":{},"outputs":[],"source":["<p><code>src</code>: input image</p>\n","<p><code>ddepth</code>: output image depth, see combinations; in the case of 8-bit input images it will result in truncated derivatives</p>\n","<p><code>dx</code>: order of the derivative x</p>\n","<p><code>dx</code>: order of the derivative y</p>\n","<p><code>ksize</code> size of the extended Sobel kernel; it must be 1, 3, 5, or 7</p>\n"]},{"cell_type":"markdown","id":"9cf79fdb-b2bf-428f-aef8-a5a666548d94","metadata":{},"outputs":[],"source":["dx = 1 represents the derivative in the x-direction.  The function approximates  the derivative by  convolving   the image with the following kernel  \n"]},{"cell_type":"markdown","id":"7539ae19-d947-428f-81d2-9ad83ef79e11","metadata":{},"outputs":[],"source":["\\begin{bmatrix} \n","1 & 0 & -1 \\\\\\\\\\\\\n","2 & 0 & -2 \\\\\\\\\n","1 & 0 & -1 \n","\\end{bmatrix}\n"]},{"cell_type":"markdown","id":"2d4ca42c-b2cc-467d-bf56-b452748c7030","metadata":{},"outputs":[],"source":["We can apply the function:\n"]},{"cell_type":"code","id":"b779a0de-f13c-45f0-8f55-2bfd3e3a62bb","metadata":{},"outputs":[],"source":["ddepth = cv2.CV_16S\n# Applys the filter on the image in the X direction\ngrad_x = cv2.Sobel(src=img_gray, ddepth=ddepth, dx=1, dy=0, ksize=3)"]},{"cell_type":"markdown","id":"e63bc4cd-905e-4a3a-a7e3-27868580f006","metadata":{},"outputs":[],"source":["We can plot the result \n"]},{"cell_type":"code","id":"af0e704e-1447-4a4e-ab51-e767820b74c9","metadata":{},"outputs":[],"source":["plt.imshow(grad_x,cmap='gray')"]},{"cell_type":"markdown","id":"01418471-f9e6-4d4f-8adb-aa01921b39c8","metadata":{},"outputs":[],"source":["dy=1 represents the derivative in the y-direction.  The function approximates  the derivative by  convolving   the image with the following kernel \n"]},{"cell_type":"markdown","id":"716f2950-b017-4b8c-8241-19f455bc426a","metadata":{},"outputs":[],"source":["\\begin{bmatrix} \n","\\ \\ 1 & \\ \\ 2 & \\ \\ 1 \\\\\\\\\\\\\n","\\ \\ 0 & \\ \\ 0 & \\ \\ 0 \\\\\\\\\n","-1 & -2 & -1 \n","\\end{bmatrix} \n"]},{"cell_type":"markdown","id":"411e2fd8-29ed-4fbe-9242-13d913f8df77","metadata":{},"outputs":[],"source":["We can apply the function and plot the result\n"]},{"cell_type":"code","id":"0e9e861b-bfb3-4a15-aece-4ac70a50c57a","metadata":{},"outputs":[],"source":["# Applys the filter on the image in the X direction\ngrad_y = cv2.Sobel(src=img_gray, ddepth=ddepth, dx=0, dy=1, ksize=3)\nplt.imshow(grad_y,cmap='gray')"]},{"cell_type":"markdown","id":"8b0057ba-2343-44dd-881b-7f283f807244","metadata":{},"outputs":[],"source":[" We can approximate the  gradient by  calculating absolute values, and converts the result to 8-bit:\n"]},{"cell_type":"code","id":"6217ad94-e909-4144-a00f-a55e8d04595d","metadata":{},"outputs":[],"source":["# Converts the values back to a number between 0 and 255\nabs_grad_x = cv2.convertScaleAbs(grad_x)\nabs_grad_y = cv2.convertScaleAbs(grad_y)"]},{"cell_type":"markdown","id":"4e39303f-fa33-4129-9fb6-08567f89ab3f","metadata":{},"outputs":[],"source":["Then apply the  function <code>addWeighted</code> to  calculates the sum of two arrays as follows:\n"]},{"cell_type":"code","id":"e37da7dc-0d01-4f1b-a116-a1546d516ea3","metadata":{},"outputs":[],"source":["# Adds the derivative in the X and Y direction\ngrad = cv2.addWeighted(abs_grad_x, 0.5, abs_grad_y, 0.5, 0)"]},{"cell_type":"markdown","id":"e2b6dc30-0033-4e3b-a447-5a70fad0862a","metadata":{},"outputs":[],"source":["We then plot the results, we see the image with lines have high-intensity values representing a large  gradient   \n"]},{"cell_type":"code","id":"3f286a58-2572-4578-b4ef-c206c6267f36","metadata":{},"outputs":[],"source":["# Make the figure bigger and renders the image\nplt.figure(figsize=(10,10))\nplt.imshow(grad,cmap='gray')"]},{"cell_type":"markdown","id":"e258480e-7a9e-440f-908a-b51c8415b515","metadata":{},"outputs":[],"source":["## Median\n","\n","Median filters find the median of all the pixels under the kernel area and the central element is replaced with this median value. \n"]},{"cell_type":"markdown","id":"6f745fa1-7aca-4ec6-a32b-fd160085eba8","metadata":{},"outputs":[],"source":["We can apply median filters to regular  images but let’s see how we can use  a median filter to improve segmentation.   Consider the cameraman example \n"]},{"cell_type":"code","id":"59e0c8da-68dc-4ccb-a9b0-5c91deb54be6","metadata":{},"outputs":[],"source":["# Load the camera man image\nimage = cv2.imread(\"cameraman.jpeg\",cv2.IMREAD_GRAYSCALE)\n# Make the image larger when it renders\nplt.figure(figsize=(10,10))\n# Renders the image\nplt.imshow(image,cmap=\"gray\")"]},{"cell_type":"markdown","id":"21a9d62a-c1bd-47d0-a651-10a012a36a4e","metadata":{},"outputs":[],"source":["Now let's apply a Median Filter by using the `medianBlur` function. The parameters for this function are `src`: The image and `ksize`: Kernel size\n"]},{"cell_type":"code","id":"fadfd914-3050-4339-954c-855b463c1f94","metadata":{},"outputs":[],"source":["# Filter the image using Median Blur with a kernel of size 5\nfiltered_image = cv2.medianBlur(image, 5)\n# Make the image larger when it renders\nplt.figure(figsize=(10,10))\n# Renders the image\nplt.imshow(filtered_image,cmap=\"gray\")"]},{"cell_type":"markdown","id":"75eee79a-dbc9-490d-bb25-4aaa90bfc021","metadata":{},"outputs":[],"source":["We would like to find the cameraman, but median filtering captures some of the background.\n","\n","## Threshold Function Parameters\n","\n","`src`: The image to use\n","`thresh`: The threshold\n","`maxval`: The maxval to use\n","`type`: Type of filtering\n","\n","The threshold function works by looking at each pixel's grayscale value and assigning a value if it is below the threshold and another value if it is above the threshold. In our example the threshold is 0 (black) and the type is binary inverse so if a value is above the threshold the assigned value is 0 (black) and if it is below or equals the threshold the maxval 255 (white) is used. So if the pixel is 0 black it is assigned 255 (white) and if the pixel is not black then it is assigned black which is what THRESH_BINARY_INV tells OpenCV to do. This is how it would work without THRESH_OTSU.\n","\n","Since we are using THRESH_OTSU it means that OpenCV will decide an optimal threshold. In our example below the threshold, we provide does not get used in the filter OpenCV will use an optimal one.\n"]},{"cell_type":"code","id":"30957609-29fd-42f7-b446-b1c6c103f751","metadata":{},"outputs":[],"source":["# Returns ret which is the threshold used and outs which is the image\nret, outs = cv2.threshold(src = image, thresh = 0, maxval = 255, type = cv2.THRESH_OTSU+cv2.THRESH_BINARY_INV)\n\n# Make the image larger when it renders\nplt.figure(figsize=(10,10))\n\n# Render the image\nplt.imshow(outs, cmap='gray')"]},{"cell_type":"markdown","id":"d2432b43-fead-49c2-b5e0-da00becceaf4","metadata":{},"outputs":[],"source":["Because those elements are mostly  zeros the median filter will filter out accordingly:  \n"]},{"cell_type":"markdown","id":"dd20aef4-6205-45fd-abb6-54e90d7e8896","metadata":{},"outputs":[],"source":["<h2>Authors</h2>\n"]},{"cell_type":"markdown","id":"060d9c3b-eabb-4586-ba48-23c515de50bb","metadata":{},"outputs":[],"source":[" [Joseph Santarcangelo](https://www.linkedin.com/in/joseph-s-50398b136/?utm_email=Email&utm_source=Nurture&utm_content=000026UJ&utm_term=10006555&utm_campaign=PLACEHOLDER&utm_id=SkillsNetwork-Courses-IBMDeveloperSkillsNetwork-CV0101EN-Coursera-25797139) has a PhD in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD.\n"]},{"cell_type":"markdown","id":"944b7f55-9a6e-4e02-921a-8e08e5dd463d","metadata":{},"outputs":[],"source":["# References\n"]},{"cell_type":"markdown","id":"5dc3e735-637b-48cc-a9e6-e933c90b07ac","metadata":{},"outputs":[],"source":["[1]  Images were taken from: [https://homepages.cae.wisc.edu/~ece533/images/](https://homepages.cae.wisc.edu/~ece533/images/?utm_email=Email&utm_source=Nurture&utm_content=000026UJ&utm_term=10006555&utm_campaign=PLACEHOLDER&utm_id=SkillsNetwork-Courses-IBMDeveloperSkillsNetwork-CV0101EN-Coursera-25797139)\n","\n","[2]  <a href='https://pillow.readthedocs.io/en/stable/index.html'>Pillow Docs</a>\n","\n","[3]  <a href='https://opencv.org/'>Open CV</a>\n","\n","[4] Gonzalez, Rafael C., and Richard E. Woods. \"Digital image processing.\" (2017).\n","\n","[5 ] Jian, Wushuai, Xueyan Sun, and Shuqian Luo. \"Computer-aided diagnosis of breast microcalcifications based on dual-tree complex wavelet transform.\" Biomedical engineering online 11.1 (2012): 1-12.\n"]},{"cell_type":"markdown","id":"169ec230-d9fa-48f3-b58c-72915121b221","metadata":{},"outputs":[],"source":["<!--<h2>Change Log</h2>-->\n"]},{"cell_type":"markdown","id":"8c506309-2ced-418a-b96d-d800d97fa970","metadata":{},"outputs":[],"source":["<!--<table>\n","    <tr>\n","        <th>Date (YYYY-MM-DD)</th>\n","        <th>Version</th>\n","        <th>Changed By</th>\n","        <th>Change Description</th>\n","    </tr>\n","    <tr>\n","        <td>2020-07-20</td>\n","        <td>0.2</td>\n","        <td>Azim</td>\n","        <td>Modified Multiple Areas</td>\n","    </tr>\n","    <tr>\n","        <td>2020-07-17</td>\n","        <td>0.1</td>\n","        <td>Azim</td>\n","        <td>Created Lab Template</td>\n","    </tr>\n","</table>\n","-->\n"]},{"cell_type":"markdown","id":"5479badb-5b53-4118-8de6-76bcfdb24085","metadata":{},"outputs":[],"source":["<h3 align=\"center\"> &#169; IBM Corporation. All rights reserved. <h3/>\n"]}],"metadata":{"kernelspec":{"display_name":"Python","language":"python","name":"conda-env-python-py"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"prev_pub_hash":"3f651c294656c6dc8e2f540858320439feead0b7f39236519657d07642ac7e8d"},"nbformat":4,"nbformat_minor":4}